{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9583dadc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6261f0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any, Annotated, Literal\n",
    "from typing_extensions import TypedDict\n",
    "import json\n",
    "from datetime import datetime\n",
    "import html\n",
    "\n",
    "# LangChain and LangGraph imports\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Tool imports\n",
    "from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import ArxivAPIWrapper, WikipediaAPIWrapper\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "# Environment setup\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf313c10",
   "metadata": {},
   "source": [
    "# ENHANCED STATE SCHEMA WITH MEMORY AND CONTEXT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d288457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ================================================================================\n",
    "# ENHANCED STATE SCHEMA WITH MEMORY AND CONTEXT\n",
    "# ================================================================================\n",
    "\n",
    "class ConversationState(TypedDict):\n",
    "    \"\"\"Enhanced state schema with conversation memory and context\"\"\"\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "    user_context: Dict[str, Any]  # Store user preferences, history, etc.\n",
    "    tool_results_cache: Dict[str, Any]  # Cache recent tool results\n",
    "    conversation_summary: str  # Summary of conversation so far\n",
    "    error_count: int  # Track errors for fallback strategies\n",
    "    last_tool_used: str  # Track last successful tool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cd559a",
   "metadata": {},
   "source": [
    "# CUSTOM TOOLS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06922297",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================================================================================\n",
    "# CUSTOM TOOLS\n",
    "# ================================================================================\n",
    "\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Perform mathematical calculations safely.\n",
    "    \n",
    "    Args:\n",
    "        expression: Mathematical expression to evaluate (e.g., \"2 + 3 * 4\")\n",
    "    \n",
    "    Returns:\n",
    "        Result of the calculation or error message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Safe evaluation - only allow basic math operations\n",
    "        allowed_chars = set('0123456789+-*/.() ')\n",
    "        if not all(c in allowed_chars for c in expression):\n",
    "            return \"Error: Invalid characters in expression. Only numbers and basic operators (+, -, *, /, parentheses) are allowed.\"\n",
    "        \n",
    "        result = eval(expression)\n",
    "        return f\"Result: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error calculating '{expression}': {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def code_analyzer(code: str, language: str = \"python\") -> str:\n",
    "    \"\"\"\n",
    "    Analyze code for basic syntax and provide simple feedback.\n",
    "    \n",
    "    Args:\n",
    "        code: Code snippet to analyze\n",
    "        language: Programming language (default: python)\n",
    "    \n",
    "    Returns:\n",
    "        Basic analysis of the code\n",
    "    \"\"\"\n",
    "    try:\n",
    "        analysis = {\n",
    "            \"language\": language,\n",
    "            \"lines\": len(code.split('\\n')),\n",
    "            \"characters\": len(code),\n",
    "            \"contains_functions\": \"def \" in code if language == \"python\" else \"function \" in code,\n",
    "            \"contains_classes\": \"class \" in code if language == \"python\" else False,\n",
    "            \"contains_imports\": any(line.strip().startswith(('import ', 'from ')) for line in code.split('\\n')) if language == \"python\" else False\n",
    "        }\n",
    "        \n",
    "        feedback = f\"\"\"\n",
    "Code Analysis for {language}:\n",
    "- Lines of code: {analysis['lines']}\n",
    "- Total characters: {analysis['characters']}\n",
    "- Contains functions: {analysis['contains_functions']}\n",
    "- Contains classes: {analysis['contains_classes']}\n",
    "- Contains imports: {analysis['contains_imports']}\n",
    "        \"\"\"\n",
    "        \n",
    "        if language == \"python\":\n",
    "            try:\n",
    "                compile(code, '<string>', 'exec')\n",
    "                feedback += \"\\n- Syntax: Valid Python syntax\"\n",
    "            except SyntaxError as e:\n",
    "                feedback += f\"\\n- Syntax Error: {str(e)}\"\n",
    "        \n",
    "        return feedback.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error analyzing code: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def weather_info(location: str) -> str:\n",
    "    \"\"\"\n",
    "    Get weather information for a location (simulated for demo).\n",
    "    \n",
    "    Args:\n",
    "        location: City or location name\n",
    "    \n",
    "    Returns:\n",
    "        Weather information\n",
    "    \"\"\"\n",
    "    # Simulated weather data - in real implementation, use weather API\n",
    "    import random\n",
    "    \n",
    "    weather_conditions = [\"sunny\", \"cloudy\", \"rainy\", \"partly cloudy\", \"windy\"]\n",
    "    temperature = random.randint(15, 35)\n",
    "    condition = random.choice(weather_conditions)\n",
    "    \n",
    "    return f\"\"\"\n",
    "Weather for {location}:\n",
    "- Temperature: {temperature}Â°C\n",
    "- Condition: {condition.title()}\n",
    "- Humidity: {random.randint(40, 80)}%\n",
    "- Wind Speed: {random.randint(5, 25)} km/h\n",
    "    \"\"\".strip()\n",
    "\n",
    "@tool\n",
    "def file_content_generator(file_type: str, content_description: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate sample file content based on type and description.\n",
    "    \n",
    "    Args:\n",
    "        file_type: Type of file (e.g., 'csv', 'json', 'python', 'markdown')\n",
    "        content_description: Description of what the file should contain\n",
    "    \n",
    "    Returns:\n",
    "        Generated file content\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if file_type.lower() == 'csv':\n",
    "            return f\"\"\"# Sample CSV for: {content_description}\n",
    "name,age,city,score\n",
    "Alice,25,New York,85\n",
    "Bob,30,London,92\n",
    "Charlie,35,Tokyo,78\n",
    "Diana,28,Paris,88\"\"\"\n",
    "\n",
    "        elif file_type.lower() == 'json':\n",
    "            sample_data = {\n",
    "                \"description\": content_description,\n",
    "                \"data\": [\n",
    "                    {\"id\": 1, \"name\": \"Item 1\", \"value\": 100},\n",
    "                    {\"id\": 2, \"name\": \"Item 2\", \"value\": 250},\n",
    "                    {\"id\": 3, \"name\": \"Item 3\", \"value\": 175}\n",
    "                ],\n",
    "                \"metadata\": {\n",
    "                    \"created\": datetime.now().isoformat(),\n",
    "                    \"version\": \"1.0\"\n",
    "                }\n",
    "            }\n",
    "            return json.dumps(sample_data, indent=2)\n",
    "\n",
    "        elif file_type.lower() == 'python':\n",
    "            return f'''\"\"\"\n",
    "{content_description}\n",
    "\"\"\"\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for {content_description}\"\"\"\n",
    "    print(\"Hello, World!\")\n",
    "    \n",
    "    # Add your code here\n",
    "    data = [1, 2, 3, 4, 5]\n",
    "    result = process_data(data)\n",
    "    print(f\"Result: {{result}}\")\n",
    "\n",
    "def process_data(data):\n",
    "    \"\"\"Process the input data\"\"\"\n",
    "    return sum(data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "        elif file_type.lower() == 'markdown':\n",
    "            return f\"\"\"# {content_description}\n",
    "\n",
    "## Overview\n",
    "This document covers {content_description.lower()}.\n",
    "\n",
    "## Key Points\n",
    "- Point 1: Important information\n",
    "- Point 2: Additional details\n",
    "- Point 3: Summary notes\n",
    "\n",
    "## Code Example\n",
    "```python\n",
    "def example_function():\n",
    "    return \"Hello, World!\"\n",
    "```\n",
    "\n",
    "## Conclusion\n",
    "This covers the basics of {content_description.lower()}.\n",
    "\"\"\"\n",
    "\n",
    "        else:\n",
    "            return f\"Sample content for {file_type} file:\\n{content_description}\\n\\nGenerated on: {datetime.now()}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error generating {file_type} content: {str(e)}\"\n",
    "\n",
    "# ================================================================================\n",
    "# TOOL INITIALIZATION\n",
    "# ================================================================================\n",
    "\n",
    "def initialize_tools():\n",
    "    \"\"\"Initialize all available tools\"\"\"\n",
    "    \n",
    "    # Academic research tools\n",
    "    arxiv_wrapper = ArxivAPIWrapper(top_k_results=3, doc_content_chars_max=1000)\n",
    "    arxiv_tool = ArxivQueryRun(\n",
    "        api_wrapper=arxiv_wrapper,\n",
    "        description=\"Search academic papers on arXiv. Best for recent research papers and preprints.\"\n",
    "    )\n",
    "    \n",
    "    # Wikipedia for general knowledge\n",
    "    wiki_wrapper = WikipediaAPIWrapper(top_k_results=2, doc_content_chars_max=800)\n",
    "    wiki_tool = WikipediaQueryRun(\n",
    "        api_wrapper=wiki_wrapper,\n",
    "        description=\"Search Wikipedia for general knowledge, definitions, and factual information.\"\n",
    "    )\n",
    "    \n",
    "    # Web search tools\n",
    "    tools_list = [arxiv_tool, wiki_tool]\n",
    "    \n",
    "    # Add Tavily if API key is available\n",
    "    if os.getenv(\"TAVILY_API_KEY\"):\n",
    "        tavily_tool = TavilySearchResults(\n",
    "            max_results=5,\n",
    "            description=\"Search the web for recent news, current events, and real-time information.\"\n",
    "        )\n",
    "        tools_list.append(tavily_tool)\n",
    "    \n",
    "    # Add DuckDuckGo as fallback web search\n",
    "    try:\n",
    "        ddg_wrapper = DuckDuckGoSearchAPIWrapper(max_results=5)\n",
    "        ddg_tool = DuckDuckGoSearchRun(\n",
    "            api_wrapper=ddg_wrapper,\n",
    "            description=\"Search the web using DuckDuckGo for current information and news.\"\n",
    "        )\n",
    "        tools_list.append(ddg_tool)\n",
    "    except Exception as e:\n",
    "        print(f\"Note: DuckDuckGo search not available due to error: {e}\")\n",
    "    \n",
    "    # Add custom tools\n",
    "    tools_list.extend([\n",
    "        calculator,\n",
    "        code_analyzer,\n",
    "        weather_info,\n",
    "        file_content_generator\n",
    "    ])\n",
    "    \n",
    "    return tools_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ed4781",
   "metadata": {},
   "source": [
    "# LLM WITH MULTIPLE MODELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a504486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EnhancedLLM:\n",
    "    \"\"\"Enhanced LLM class with fallback models and error handling\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.primary_model = \"llama-3.3-70b-versatile\"  # Fast, capable model\n",
    "        self.fallback_models = [\n",
    "            \"llama-3.2-90b-text-preview\",  # More capable for complex tasks\n",
    "            \"mixtral-8x7b-32768\",          # Good for reasoning\n",
    "            \"gemma2-9b-it\"                 # Lightweight fallback\n",
    "        ]\n",
    "        self.current_model = self.primary_model\n",
    "        \n",
    "    def get_llm(self, temperature: float = 0.1, max_tokens: int = 2000):\n",
    "        \"\"\"Get LLM instance with current model\"\"\"\n",
    "        try:\n",
    "            return ChatGroq(\n",
    "                model=self.current_model,\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error with model {self.current_model}: {e}\")\n",
    "            # Try fallback models\n",
    "            for model in self.fallback_models:\n",
    "                try:\n",
    "                    self.current_model = model\n",
    "                    return ChatGroq(\n",
    "                        model=model,\n",
    "                        temperature=temperature,\n",
    "                        max_tokens=max_tokens\n",
    "                    )\n",
    "                except:\n",
    "                    continue\n",
    "            raise Exception(\"All models failed to initialize\")\n",
    "\n",
    "# ================================================================================\n",
    "# ENHANCED NODES WITH ERROR HANDLING AND CONTEXT\n",
    "# ================================================================================\n",
    "\n",
    "def create_enhanced_nodes(tools: List, llm_manager: EnhancedLLM):\n",
    "    \"\"\"Create enhanced nodes with better error handling and context management\"\"\"\n",
    "    \n",
    "    def context_aware_llm(state: ConversationState) -> ConversationState:\n",
    "        \"\"\"Enhanced LLM node with context awareness and error handling\"\"\"\n",
    "        try:\n",
    "            # Get current LLM\n",
    "            llm = llm_manager.get_llm()\n",
    "            llm_with_tools = llm.bind_tools(tools=tools)\n",
    "            \n",
    "            # Add system message with context if this is the first message\n",
    "            messages = state[\"messages\"]\n",
    "            if not any(isinstance(msg, SystemMessage) for msg in messages):\n",
    "                system_prompt = f\"\"\"You are an advanced AI assistant with access to multiple tools. \n",
    "Current conversation summary: {state.get('conversation_summary', 'New conversation')}\n",
    "User context: {state.get('user_context', {})}\n",
    "Last successful tool: {state.get('last_tool_used', 'None')}\n",
    "\n",
    "Guidelines:\n",
    "1. Use tools when they can provide better, more current, or specialized information\n",
    "2. Be concise but comprehensive in your responses  \n",
    "3. If a tool fails, try alternative approaches\n",
    "4. Maintain conversation context and refer to previous interactions when relevant\n",
    "5. For complex queries, break them down and use multiple tools if needed\"\"\"\n",
    "                \n",
    "                messages = [SystemMessage(content=system_prompt)] + messages\n",
    "            \n",
    "            # Invoke LLM with tools\n",
    "            response = llm_with_tools.invoke(messages)\n",
    "            \n",
    "            # Update state\n",
    "            new_state = {\n",
    "                \"messages\": [response],\n",
    "                \"error_count\": 0  # Reset error count on success\n",
    "            }\n",
    "            \n",
    "            return new_state\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error in LLM processing: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            \n",
    "            # Increment error count\n",
    "            error_count = state.get(\"error_count\", 0) + 1\n",
    "            \n",
    "            # Fallback response\n",
    "            fallback_response = AIMessage(\n",
    "                content=f\"I encountered an issue processing your request. Error count: {error_count}. \"\n",
    "                       f\"Let me try a different approach or please rephrase your question.\"\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                \"messages\": [fallback_response],\n",
    "                \"error_count\": error_count\n",
    "            }\n",
    "    \n",
    "    def enhanced_tool_node(state: ConversationState) -> ConversationState:\n",
    "        \"\"\"Enhanced tool node with caching and error handling\"\"\"\n",
    "        try:\n",
    "            # Use standard ToolNode but with enhanced error handling\n",
    "            tool_node = ToolNode(tools)\n",
    "            result = tool_node.invoke(state)\n",
    "            \n",
    "            # Cache successful tool results\n",
    "            if \"tool_results_cache\" not in state:\n",
    "                state[\"tool_results_cache\"] = {}\n",
    "            \n",
    "            # Update last successful tool\n",
    "            last_message = result[\"messages\"][-1] if result[\"messages\"] else None\n",
    "            if last_message and hasattr(last_message, 'name'):\n",
    "                result[\"last_tool_used\"] = last_message.name\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Tool execution error: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            \n",
    "            # Return error message\n",
    "            error_response = AIMessage(\n",
    "                content=f\"I encountered an error while using the tools: {str(e)}. \"\n",
    "                       \"Let me try to help you in a different way.\"\n",
    "            )\n",
    "            \n",
    "            return {\"messages\": [error_response]}\n",
    "    \n",
    "    return context_aware_llm, enhanced_tool_node\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a36a133",
   "metadata": {},
   "source": [
    "# CONVERSATION MANAGER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a62d53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# CONVERSATION MANAGER\n",
    "# ================================================================================\n",
    "\n",
    "class ConversationManager:\n",
    "    \"\"\"Manages conversation history and context\"\"\"\n",
    "    \n",
    "    def __init__(self, max_history: int = 20):\n",
    "        self.max_history = max_history\n",
    "        \n",
    "    def summarize_conversation(self, messages: List[AnyMessage]) -> str:\n",
    "        \"\"\"Create a summary of the conversation\"\"\"\n",
    "        if len(messages) < 4:\n",
    "            return \"New conversation\"\n",
    "        \n",
    "        # Simple summarization - count topics discussed\n",
    "        topics = set()\n",
    "        for msg in messages:\n",
    "            if isinstance(msg, HumanMessage):\n",
    "                content = msg.content.lower()\n",
    "                if any(word in content for word in ['weather', 'temperature', 'climate']):\n",
    "                    topics.add('weather')\n",
    "                if any(word in content for word in ['calculate', 'math', 'equation']):\n",
    "                    topics.add('calculations')\n",
    "                if any(word in content for word in ['code', 'programming', 'python']):\n",
    "                    topics.add('programming')\n",
    "                if any(word in content for word in ['research', 'paper', 'study']):\n",
    "                    topics.add('research')\n",
    "        \n",
    "        if topics:\n",
    "            return f\"Discussion topics: {', '.join(topics)}\"\n",
    "        return f\"Conversation with {len(messages)//2} exchanges\"\n",
    "    \n",
    "    def trim_history(self, messages: List[AnyMessage]) -> List[AnyMessage]:\n",
    "        \"\"\"Trim conversation history to manageable size\"\"\"\n",
    "        if len(messages) <= self.max_history:\n",
    "            return messages\n",
    "        \n",
    "        # Keep system message if present, plus recent messages\n",
    "        system_msgs = [msg for msg in messages if isinstance(msg, SystemMessage)]\n",
    "        recent_msgs = messages[-self.max_history:]\n",
    "        \n",
    "        return system_msgs + recent_msgs\n",
    "\n",
    "# ================================================================================\n",
    "# MAIN CHATBOT CLASS\n",
    "# ================================================================================\n",
    "\n",
    "class AdvancedChatbot:\n",
    "    \"\"\"Advanced chatbot with multiple tools and enhanced features\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tools = initialize_tools()\n",
    "        self.llm_manager = EnhancedLLM()\n",
    "        self.conversation_manager = ConversationManager()\n",
    "        self.memory = MemorySaver()\n",
    "        self.graph = self._build_graph()\n",
    "        \n",
    "        print(f\"â Initialized chatbot with {len(self.tools)} tools:\")\n",
    "        for tool in self.tools:\n",
    "            print(f\"   - {tool.name}: {tool.description}\")\n",
    "    \n",
    "    def _build_graph(self) -> StateGraph:\n",
    "        \"\"\"Build the enhanced conversation graph\"\"\"\n",
    "        \n",
    "        # Create enhanced nodes\n",
    "        context_llm, enhanced_tools = create_enhanced_nodes(self.tools, self.llm_manager)\n",
    "        \n",
    "        # Build graph\n",
    "        builder = StateGraph(ConversationState)\n",
    "        \n",
    "        # Add nodes\n",
    "        builder.add_node(\"context_llm\", context_llm)\n",
    "        builder.add_node(\"enhanced_tools\", enhanced_tools)\n",
    "        builder.add_node(\"conversation_manager\", self._manage_conversation)\n",
    "        \n",
    "        # Add edges\n",
    "        builder.add_edge(START, \"conversation_manager\")\n",
    "        builder.add_edge(\"conversation_manager\", \"context_llm\")\n",
    "        \n",
    "        # Conditional edge from LLM\n",
    "        builder.add_conditional_edges(\n",
    "            \"context_llm\",\n",
    "            tools_condition,\n",
    "            {\n",
    "                \"tools\": \"enhanced_tools\",\n",
    "                \"__end__\": END\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Edge from tools back to LLM\n",
    "        builder.add_edge(\"enhanced_tools\", \"context_llm\")\n",
    "        \n",
    "        # Compile with memory\n",
    "        return builder.compile(checkpointer=self.memory)\n",
    "    \n",
    "    def _manage_conversation(self, state: ConversationState) -> ConversationState:\n",
    "        \"\"\"Manage conversation context and history\"\"\"\n",
    "        \n",
    "        # Trim history if needed\n",
    "        messages = self.conversation_manager.trim_history(state[\"messages\"])\n",
    "        \n",
    "        # Update conversation summary\n",
    "        summary = self.conversation_manager.summarize_conversation(messages)\n",
    "        \n",
    "        # Initialize user context if not present\n",
    "        user_context = state.get(\"user_context\", {})\n",
    "        \n",
    "        return {\n",
    "            \"messages\": messages,\n",
    "            \"conversation_summary\": summary,\n",
    "            \"user_context\": user_context,\n",
    "            \"tool_results_cache\": state.get(\"tool_results_cache\", {}),\n",
    "            \"error_count\": state.get(\"error_count\", 0),\n",
    "            \"last_tool_used\": state.get(\"last_tool_used\", \"\")\n",
    "        }\n",
    "    \n",
    "    def chat(self, message: str, thread_id: str = \"default\") -> str:\n",
    "        \"\"\"Main chat interface\"\"\"\n",
    "        try:\n",
    "            # Create initial state\n",
    "            initial_state = {\n",
    "                \"messages\": [HumanMessage(content=message)],\n",
    "                \"user_context\": {},\n",
    "                \"tool_results_cache\": {},\n",
    "                \"conversation_summary\": \"\",\n",
    "                \"error_count\": 0,\n",
    "                \"last_tool_used\": \"\"\n",
    "            }\n",
    "            \n",
    "            # Run the graph\n",
    "            config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "            result = self.graph.invoke(initial_state, config)\n",
    "            \n",
    "            # Extract final response\n",
    "            final_messages = result[\"messages\"]\n",
    "            ai_messages = [msg for msg in final_messages if isinstance(msg, AIMessage)]\n",
    "            \n",
    "            if ai_messages:\n",
    "                return ai_messages[-1].content\n",
    "            else:\n",
    "                return \"I'm sorry, I couldn't generate a response. Please try again.\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"Error in chat processing: {str(e)}. Please try rephrasing your question.\"\n",
    "    \n",
    "    def get_conversation_history(self, thread_id: str = \"default\") -> List[Dict]:\n",
    "        \"\"\"Get conversation history for a thread\"\"\"\n",
    "        try:\n",
    "            config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "            history = []\n",
    "            \n",
    "            for state in self.graph.get_state_history(config):\n",
    "                messages = state.values.get(\"messages\", [])\n",
    "                for msg in messages:\n",
    "                    if isinstance(msg, (HumanMessage, AIMessage)):\n",
    "                        history.append({\n",
    "                            \"type\": \"human\" if isinstance(msg, HumanMessage) else \"ai\",\n",
    "                            \"content\": msg.content,\n",
    "                            \"timestamp\": datetime.now().isoformat()\n",
    "                        })\n",
    "            \n",
    "            return history\n",
    "        except:\n",
    "            return []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58498f36",
   "metadata": {},
   "source": [
    "# EXAMPLE USAGE AND TESTING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8d34c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3233798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# ================================================================================\n",
    "\n",
    "def run_examples():\n",
    "    \"\"\"Run example conversations to demonstrate capabilities\"\"\"\n",
    "    \n",
    "    # Initialize chatbot\n",
    "    chatbot = AdvancedChatbot()\n",
    "    \n",
    "    # Example conversations\n",
    "    examples = [\n",
    "        \"Calculate the area of a circle with radius 5\",\n",
    "        \"What's the latest research on quantum computing?\",\n",
    "        \"Analyze this Python code: def hello(): print('Hello World')\",\n",
    "        \"What's the weather like in Tokyo?\",\n",
    "        \"Generate a CSV file for student grades\",\n",
    "        \"Who is Nikola Tesla?\",\n",
    "        \"Find recent news about artificial intelligence in healthcare\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ADVANCED CHATBOT DEMONSTRATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for i, example in enumerate(examples, 1):\n",
    "        print(f\"\\nð¤ Example {i}: {example}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        try:\n",
    "            response = chatbot.chat(example, thread_id=f\"demo_{i}\")\n",
    "            print(f\"â Response: {response}\")\n",
    "        except Exception as e:\n",
    "            print(f\"â Error: {str(e)}\")\n",
    "        \n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a77c9a3",
   "metadata": {},
   "source": [
    "# JUPYTER NOTEBOOK INTEGRATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a9f88ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ð¯ Run display_chatbot_interface() to start the interactive chat!\n",
      "ð¯ Run run_examples() to see demonstration examples!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def display_chatbot_interface():\n",
    "    \"\"\"Display an interactive interface for Jupyter\"\"\"\n",
    "    from IPython.display import display, HTML, clear_output\n",
    "    import ipywidgets as widgets\n",
    "    \n",
    "    # Initialize chatbot\n",
    "    chatbot = AdvancedChatbot()\n",
    "    \n",
    "    # Create output with scroll + full width\n",
    "    # output = widgets.Output(layout=widgets.Layout(\n",
    "    #     width='80%',\n",
    "    #     height='400px',\n",
    "    #     overflow='auto',\n",
    "    #     border='1px solid #ccc',\n",
    "    #     padding='10px',\n",
    "    #    # white_space='normal'\n",
    "    # ))\n",
    "    output= widgets.VBox(layout=widgets.Layout(\n",
    "    width='100%',\n",
    "    height='400px',\n",
    "    overflow_y='auto',\n",
    "    border='1px solid #ccc',\n",
    "    padding='10px',\n",
    "))\n",
    "\n",
    "\n",
    "    \n",
    "    # Input widget\n",
    "    text_input = widgets.Text(\n",
    "        placeholder=\"Type your message here...\",\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='100%')  # changed from 70%\n",
    "    )\n",
    "    \n",
    "    # Buttons\n",
    "    send_button = widgets.Button(\n",
    "        description=\"Send\",\n",
    "        button_style='primary',\n",
    "        layout=widgets.Layout(width='100%')\n",
    "    )\n",
    "    clear_button = widgets.Button(\n",
    "        description=\"Clear\",\n",
    "        button_style='warning',\n",
    "        layout=widgets.Layout(width='100%')\n",
    "    )\n",
    "    \n",
    "    # Button container (horizontal)\n",
    "    button_box = widgets.HBox([send_button, clear_button],\n",
    "                               layout=widgets.Layout(justify_content='space-between'))\n",
    "\n",
    "    # Chat history\n",
    "    chat_history = []\n",
    "    \n",
    "\n",
    "    # def send_message(b):\n",
    "        # message = text_input.value.strip()\n",
    "        # if message:\n",
    "        #     with output:\n",
    "        #         print(f\"ð§ You: {message}\")\n",
    "        #         try:\n",
    "        #             response = chatbot.chat(message)\n",
    "        #             from IPython.display import HTML as ipyHTML, display as ipy_display\n",
    "        #             ipy_display(ipyHTML(f\"<div style='white-space: normal; word-wrap: break-word;'>ð¤ Assistant: {response}</div>\"))\n",
    "        #             chat_history.append((\"user\", message))\n",
    "        #             chat_history.append((\"assistant\", response))\n",
    "        #         except Exception as e:\n",
    "        #             print(f\"â Error: {str(e)}\")\n",
    "        #         print(\"\\n\" + \"-\" * 80 + \"\\n\")\n",
    "        #     text_input.value = \"\"\n",
    "\n",
    "\n",
    "\n",
    "    # def send_message(b):\n",
    "    #     message = text_input.value.strip()\n",
    "    #     if message:\n",
    "    #         user_html = widgets.HTML(\n",
    "    #             value=f\"<div style='white-space: normal; word-wrap: break-word;'><b>ð§ You:</b> {message}</div>\"\n",
    "    #         )\n",
    "    #         try:\n",
    "    #             response = chatbot.chat(message)\n",
    "    #             assistant_html = widgets.HTML(\n",
    "    #                 value=f\"<div style='white-space: normal; word-wrap: break-word;'><b>ð¤ Assistant:</b> {response}</div>\"\n",
    "    #             )\n",
    "    #         except Exception as e:\n",
    "    #             assistant_html = widgets.HTML(\n",
    "    #                 value=f\"<div style='color: red;'>â Error: {str(e)}</div>\"\n",
    "    #             )\n",
    "    #         output.children += (user_html, assistant_html)\n",
    "    #         chat_history.append((\"user\", message))\n",
    "    #         chat_history.append((\"assistant\", response))\n",
    "    #         text_input.value = \"\"\n",
    "\n",
    "        ## adding format_response function to format the response\n",
    "\n",
    "         \n",
    "    def format_response(response_text):\n",
    "        \"\"\"Converts bullet points and newlines to HTML format.\"\"\"\n",
    "        response_text = html.escape(response_text)\n",
    "        lines = response_text.split(\"\\n\")\n",
    "        html_lines = []\n",
    "        in_list = False\n",
    "        for line in lines:\n",
    "            if line.strip().startswith(\"* \"):\n",
    "                if not in_list:\n",
    "                    html_lines.append(\"<ul>\")\n",
    "                    in_list = True\n",
    "                html_lines.append(f\"<li>{line.strip()[2:]}</li>\")\n",
    "            else:\n",
    "                if in_list:\n",
    "                    html_lines.append(\"</ul>\")\n",
    "                    in_list = False\n",
    "                html_lines.append(f\"<p>{line}</p>\")\n",
    "        if in_list:\n",
    "            html_lines.append(\"</ul>\")\n",
    "        return \"<div style='white-space: normal; word-wrap: break-word;'>\" + \"\".join(html_lines) + \"</div>\"\n",
    "    \n",
    "    def send_message(b):\n",
    "        message = text_input.value.strip()\n",
    "        if message:\n",
    "            user_html = widgets.HTML(\n",
    "                value=f\"<div style='white-space: normal; word-wrap: break-word;'><b>ð§ You:</b> {html.escape(message)}</div>\"\n",
    "            )\n",
    "            try:\n",
    "                response = chatbot.chat(message)\n",
    "                formatted_response = format_response(response)\n",
    "                assistant_html = widgets.HTML(\n",
    "                    value=f\"<b>ð¤ Assistant:</b> {formatted_response}\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                assistant_html = widgets.HTML(\n",
    "                    value=f\"<div style='color: red;'>â Error: {str(e)}</div>\"\n",
    "                )\n",
    "            output.children += (user_html, assistant_html)\n",
    "            chat_history.append((\"user\", message))\n",
    "            chat_history.append((\"assistant\", response))\n",
    "            text_input.value = \"\"\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # def clear_chat(b):\n",
    "    #     with output:\n",
    "    #         clear_output()\n",
    "    #         chat_history.clear()\n",
    "    #         print(\"Chat cleared. Start a new conversation!\")\n",
    "\n",
    "    def clear_chat(b):\n",
    "        output.children = ()  # Clear all displayed chat messages\n",
    "        chat_history.clear()\n",
    "        print(\"Chat cleared. Start a new conversation!\")\n",
    "\n",
    "    \n",
    "    # Event handlers\n",
    "    send_button.on_click(send_message)\n",
    "    clear_button.on_click(clear_chat)\n",
    "    text_input.on_submit(lambda x: send_message(None))\n",
    "    \n",
    "    # Layout containers\n",
    "    input_area = widgets.VBox([\n",
    "        text_input,\n",
    "        button_box\n",
    "    ], layout=widgets.Layout(width='100%'))\n",
    "\n",
    "    full_ui = widgets.VBox([output, input_area],\n",
    "                           layout=widgets.Layout(width='100%', overflow_x='auto'))\n",
    "    \n",
    "    # Display\n",
    "    print(\"ð Advanced Multi-Tool Chatbot Interface\")\n",
    "    print(\"Available tools: ArXiv, Wikipedia, Web Search, Calculator, Code Analyzer, Weather, File Generator\")\n",
    "    print(\"Type your message and press Enter or click Send!\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    display(full_ui)\n",
    "    \n",
    "    return chatbot\n",
    "\n",
    "\n",
    "# Example usage in Jupyter\n",
    "if __name__ == \"__main__\":\n",
    "    # For notebook environment\n",
    "    try:\n",
    "        get_ipython()  # This will raise NameError if not in Jupyter\n",
    "        print(\"ð¯ Run display_chatbot_interface() to start the interactive chat!\")\n",
    "        print(\"ð¯ Run run_examples() to see demonstration examples!\")\n",
    "    except NameError:\n",
    "        # For script environment\n",
    "        run_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "140f524a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â Initialized chatbot with 8 tools:\n",
      "   - arxiv: Search academic papers on arXiv. Best for recent research papers and preprints.\n",
      "   - wikipedia: Search Wikipedia for general knowledge, definitions, and factual information.\n",
      "   - tavily_search_results_json: Search the web for recent news, current events, and real-time information.\n",
      "   - duckduckgo_search: Search the web using DuckDuckGo for current information and news.\n",
      "   - calculator: Perform mathematical calculations safely.\n",
      "\n",
      "Args:\n",
      "    expression: Mathematical expression to evaluate (e.g., \"2 + 3 * 4\")\n",
      "\n",
      "Returns:\n",
      "    Result of the calculation or error message\n",
      "   - code_analyzer: Analyze code for basic syntax and provide simple feedback.\n",
      "\n",
      "Args:\n",
      "    code: Code snippet to analyze\n",
      "    language: Programming language (default: python)\n",
      "\n",
      "Returns:\n",
      "    Basic analysis of the code\n",
      "   - weather_info: Get weather information for a location (simulated for demo).\n",
      "\n",
      "Args:\n",
      "    location: City or location name\n",
      "\n",
      "Returns:\n",
      "    Weather information\n",
      "   - file_content_generator: Generate sample file content based on type and description.\n",
      "\n",
      "Args:\n",
      "    file_type: Type of file (e.g., 'csv', 'json', 'python', 'markdown')\n",
      "    content_description: Description of what the file should contain\n",
      "\n",
      "Returns:\n",
      "    Generated file content\n",
      "ð Advanced Multi-Tool Chatbot Interface\n",
      "Available tools: ArXiv, Wikipedia, Web Search, Calculator, Code Analyzer, Weather, File Generator\n",
      "Type your message and press Enter or click Send!\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Waseek\\AppData\\Local\\Temp\\ipykernel_9048\\410335709.py:156: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').\n",
      "  text_input.on_submit(lambda x: send_message(None))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee82c5bf53345e0a461477b02d3b656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(layout=Layout(border_bottom='1px solid #ccc', border_left='1px solid #ccc', border_right='â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.AdvancedChatbot at 0x1bc484f6090>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_chatbot_interface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8253c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5775df68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
